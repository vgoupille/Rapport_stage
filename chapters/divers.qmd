# Materials and Methods {#sec-materials-and-methods}

## Materials

catfastq to merge the reads from the 4 lanes (https://nf-co.re/rnaseq/3.14.0/)

We have 4 index to improve the quality of the sequencing Illimina first step : verify the quality of the reads we do a fastqc analysis and multiqc to have a global overview of the quality of the reads

then we remove the adapters and low quality reads with cutadapt or Trimmomatic, TrimGalore

https://cutadapt.readthedocs.io/en/stable/guide.html

https://onlinelibrary.wiley.com/doi/10.1002/imt2.107 fastp is a tool to improve the quality of the reads

2,5 coupes de queue polyG et polyX PolyG est un probl√®me fr√©quent observ√© dans les s√©ries Illumina NextSeq et NovaSeq, bas√©es sur la chimie bicolore. Ces syst√®mes utilisent deux lumi√®res diff√©rentes (rouge et verte) pour repr√©senter quatre bases : une base avec seulement un signal rouge d√©tect√© est appel√©e C ; une base avec seulement un signal vert d√©tect√© est appel√©e T ; une base avec √† la fois des lumi√®res rouge et verte d√©tect√©es est appel√©e A ; et une base sans lumi√®re d√©tect√©e est appel√©e G. Cependant, √† mesure que le s√©quen√ßage par synth√®se progresse, l'intensit√© du signal de chaque cluster d'ADN s'affaiblit progressivement. Ce probl√®me entra√Æne l'interpr√©tation erron√©e de certaines T et C comme G dans les queues de lecture, un probl√®me √©galement connu sous le nom de queue polyG.

I will use the fastp because it is more efficient and faster than cutadapt or Trimmomatic

manual : https://open.bioqueue.org/home/knowledge/showKnowledge/sig/fastp It's also available on github : https://github.com/OpenGene/fastp

I receiv the data from Genobird plateforme of sequencing the 25 april 2025 https://umr1087.univ-nantes.fr/research/core-facilities/genobird Two types of sequencing data : - bcl files (raw data from the plateforme of sequencing) (250go) - fastq files (processed data from the plateforme of sequencing) =\> we use this one for the moment because they remove the index from the reads (150go)

There are 4 index for Novaseq (BC_0076, BC_0077, BC_0078, BC_0079) : CAGATC, ACTTGA, TAGCTT, GGCTAC. No experimental variation (biological or technical) between the index (Just added for a better quality of sequencing with Novaseq (I'm not sure about this)).

We don't use the raw data from the plateforme of sequencing (bcl files) maybe later if I want to test to do the demultiplexing of the index (r4)

In fact the plateforme of sequencing already do a demultiplexing of the index (r4). This allows to have a better quality of sequencing with Novaseq.

So we have 8 fastq files ((R1 and R2)\*4) (one for each index) the index is removed from the R1 and R2 files the R1 file contain the sequence the R2 file contain the barcodes (r1, r2, r3) and the UMI and the index (already removed) CB_UMI_Complex consider of STARsolo consider that bardeodes are on the R2 file

Do a figure for represent the sequence (see the formation Norwich and paper of Kuchina)

I test to directly run STARsolo on the fastq files but I need more space on the server for all run I observe that we don't detect many genes and read (test on BC_0077 which is the file with the lowest size) So we decided to do a fastq quality control with fastqc and multiqc of R1 and R2 files (example in BC_0076)

R2 file is globally correct : we see the barcodes and the UMI R1 file is not correct : adapter and low quality sequences at the end of the read

of there are no different between the R1 and R2 files we could combine them in unique files (R1 and R2), for the moment we keep them separate and I test on BC_0076

We want to remove the adapters and low quality sequences detected by fastqc many poly at the end of the read

We use fastp to remove the adapters and low quality sequences detected by fastqc many poly at the end of the read before we want to do small file test we need to generate small fastq R1 and R2 files

list of the Illumina adapters : https://github.com/s-andrews/FastQC/blob/master/Configuration/contaminant_list.txt

manual of fastp : http://open.bioqueue.org/home/knowledge/showKnowledge/sig/fastp

Script to run fastp on the fastq files allow to remove adapters and low quality sequences detected by fastqc The fastq files are in the folder 0_QC/data The fastp files are in the folder 1_fastp/data

Test on 250 000 000 reads

We need to remove the sequences R1 that we don't use in our experiment

list of the sequences to remove in fastp :\
https://teichlab.github.io/scg_lib_structs/methods_html/SPLiT-seq.html

I will see the result of fastqc to find

Tr√®s bonne question ! Voici pourquoi le ‚ÄúInsert size peak : 241 bp‚Äù est coh√©rent avec les lectures R1 de 241 cycles :

‚∏ª

üîç D√©finition rapide : ‚Ä¢ Insert size (taille de l‚Äôinsert) : c‚Äôest la distance entre le d√©but de R1 et la fin de R2 sur la mol√©cule d‚ÄôADN originale, c‚Äôest-√†-dire la taille de l‚ÄôADN r√©ellement s√©quenc√© (hors adaptateurs). ‚Ä¢ Nombre de cycles : correspond au nombre de bases que le s√©quenceur lit par lecture.

‚∏ª

üìä Dans ton cas : ‚Ä¢ R1 = 241 cycles ‚Üí chaque lecture R1 peut th√©oriquement faire jusqu‚Äô√† 241 bases ‚Ä¢ R2 = 91 cycles ‚Üí R2 peut faire jusqu‚Äô√† 91 bases

Mais attention : les lectures ne couvrent pas toujours la totalit√© de l‚Äôinsert. Cela d√©pend de la taille de l‚Äôinsert fragment√© lors de la pr√©paration de la librairie.

‚∏ª

‚úÖ Pourquoi 241 bp est coh√©rent ici ? ‚Ä¢ Le ‚Äúinsert size peak‚Äù repr√©sente la valeur la plus fr√©quente des insert sizes calcul√©s en alignant les paires de lectures (R1 et R2). ‚Ä¢ Or, ici on voit que : ‚Ä¢ Le nombre de cycles de R1 est 241 ‚áí donc on peut lire jusqu‚Äô√† 241 bases sur le fragment (avant que R2 commence). ‚Ä¢ Le fait que l‚Äôinsert size pic soit √† 241 signifie que les deux lectures R1 et R2 se chevauchent √† peine ou pas du tout, et que l‚Äôinsert est environ aussi long que la lecture R1.

Donc :

Le pic d‚Äôinsert size √† 241 bp signifie que la plupart des fragments d‚ÄôADN (les inserts) font la m√™me longueur que la lecture R1 ‚Üí coh√©rent avec une pr√©paration o√π R2 lit le reste ou tr√®s peu de l‚Äôinsert.

‚∏ª

üß¨ Hypoth√®se probable ici : ‚Ä¢ Tu travailles probablement avec des librairies scRNA-seq adapt√©es pour des fragments courts, et tu s√©quences surtout √† fond R1 (lecture informative). ‚Ä¢ R2 est plus courte (91 cycles), souvent pour lire un barcode ou UMI ‚Üí R1 capture le bulk de l‚Äôinformation transcriptomique.

‚∏ª

üß† R√©sum√© :

Insert size = 241 bp, R1 = 241 cycles ‚Üí la lecture R1 couvre quasiment toute la mol√©cule. C‚Äôest donc coh√©rent et attendu dans ce type de design.

--adapter_sequence_r2=AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\
--adapter_sequence=TGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA

```         
  Le graphique que tu montres provient de FastQC (via MultiQC) et pr√©sente les niveaux de duplication des s√©quences dans 4 √©chantillons. Voici une explication de la variabilit√© entre les index observ√©s :
```

‚∏ª

üîç Comprendre le graphe : ‚Ä¢ Axe X : niveau de duplication (combien de fois chaque s√©quence appara√Æt). ‚Ä¢ Axe Y : pourcentage de la librairie. ‚Ä¢ Lignes vertes : √©chantillons avec peu de duplication (bon signe). ‚Ä¢ Lignes rouges : √©chantillons avec forte duplication (plusieurs s√©quences pr√©sentes en tr√®s grand nombre).

‚∏ª

üìå Pourquoi observe-t-on une telle variabilit√© entre √©chantillons/index ? 1. üìö Complexit√© de la librairie : ‚Ä¢ Les √©chantillons avec peu de duplication (courbe verte) ont probablement une bonne complexit√© ‚Üí beaucoup de s√©quences uniques, peu de redondance. ‚Ä¢ Ceux avec forte duplication (courbes rouges) ont une faible complexit√© ‚Üí trop de s√©quences identiques. 2. üì¶ Qualit√© ou quantit√© d‚ÄôADN/ARN initial : ‚Ä¢ Si la quantit√© de mat√©riel initial est faible, il y a un risque de suramplification lors de la PCR, ce qui entra√Æne une duplication artificielle des s√©quences. 3. üß™ Protocole de pr√©paration des librairies : ‚Ä¢ Des diff√©rences dans la pr√©paration des index ou la quantit√© d‚Äôamplification PCR peuvent induire cette variabilit√©. ‚Ä¢ Mauvaise ligation d‚Äôadaptateurs ou biais d‚Äôamplification peuvent engendrer une surrepr√©sentation de certaines s√©quences. 4. üîÑ Index/swapping ou contamination crois√©e : ‚Ä¢ Si des √©chantillons ont √©t√© mal index√©s ou qu‚Äôil y a eu du swapping d‚Äôindex, cela peut cr√©er une fausse duplication dans un √©chantillon. ‚Ä¢ Des erreurs dans le multiplexing (m√©lange d‚Äô√©chantillons mal contr√¥l√©) peuvent aussi l‚Äôexpliquer. 5. üß¨ Nature biologique de l‚Äô√©chantillon : ‚Ä¢ Certains √©chantillons biologiques peuvent contenir naturellement beaucoup de s√©quences identiques (ex : s√©quences rRNA, transcrits tr√®s abondants). ‚Ä¢ Une transcription tr√®s polaris√©e (un seul g√®ne tr√®s exprim√©) peut causer des duplications √©lev√©es.

‚∏ª

‚úÖ Que faire ensuite ? ‚Ä¢ V√©rifie les logs de pr√©paration des librairies (nombre de cycles PCR, quantit√©s initiales). ‚Ä¢ Contr√¥le la nature des s√©quences dupliqu√©es (rRNA ? contamination ? artefacts PCR ?). ‚Ä¢ Si la duplication est due √† un biais technique, envisage une normalisation, filtrage ou r√©analyse avec des m√©thodes robustes √† la duplication.

Souhaites-tu que je t‚Äôaide √† analyser un des fichiers FastQC ou MultiQC de ces √©chantillons ?

Excellente question ! Pour comprendre l‚Äôorigine de la duplication dans tes √©chantillons, tu peux suivre une d√©marche en plusieurs √©tapes. Voici comment proc√©der concr√®tement, avec des outils comme FastQC, MultiQC, et √©ventuellement un peu de bioinformatique :

‚∏ª

üß™ √âtape 1 : Identifier quels √©chantillons sont affect√©s ‚Ä¢ Dans MultiQC, regarde le nom des fichiers / √©chantillons associ√©s aux courbes rouges. ‚Ä¢ Tu peux passer ta souris sur les courbes dans le rapport MultiQC (ou cliquer sur ¬´ Summarize plot ¬ª) pour identifier les noms des √©chantillons concern√©s.

‚∏ª

üîç √âtape 2 : Inspecter le rapport FastQC individuel

Pour chaque √©chantillon avec forte duplication :

üìÅ a. Ouvre le rapport fastqc.html

Regarde particuli√®rement ces modules : 1. Per base sequence content ‚Üí S‚Äôil y a un biais fort (ex. enrichissement en G ou T), cela peut refl√©ter une amorce ou adaptateur r√©siduel. 2. Overrepresented sequences ‚Üí Si des s√©quences pr√©cises sont tr√®s abondantes, tu verras leurs s√©quences et une annotation possible (ex : ‚ÄúIllumina adapter‚Äù, ‚ÄúrRNA‚Äù‚Ä¶). 3. K-mer content ‚Üí D√©tecte des motifs courts (souvent adaptateurs ou contamination PCR) qui sont surrepr√©sent√©s.

‚∏ª

üß∞ √âtape 3 : V√©rifier la complexit√© de librairie 1. Utilise preseq (si possible) pour estimer la diversit√© de la librairie et pr√©dire combien de nouvelles s√©quences seraient trouv√©es avec plus de s√©quen√ßage. 2. V√©rifie le nombre de cycles PCR lors de la pr√©paration (si tu as acc√®s aux m√©tadonn√©es du protocole).

‚∏ª

üîé √âtape 4 : Aligner et filtrer pour comprendre 1. Alignement contre la r√©f√©rence : ‚Ä¢ Si la duplication est biologique (ex : g√®ne tr√®s exprim√©), les s√©quences dupliqu√©es s‚Äôaligneront sur le g√©nome. ‚Ä¢ Si c‚Äôest technique, tu verras des clusters de lectures identiques, souvent non align√©es ou align√©es aux m√™mes positions. 2. Filtrer les reads rRNA ou adaptateurs avec bbduk ou cutadapt.

‚∏ª

üìä √âtape 5 : Comparer les duplications avant/apr√®s nettoyage

Apr√®s avoir filtr√© ou supprim√© des s√©quences surrepr√©sent√©es (ex : adaptateurs, rRNA), relance FastQC sur les fichiers nettoy√©s pour voir si la duplication baisse.

‚∏ª

En r√©sum√© :

√âtape Objectif Outil Identifier √©chantillons affect√©s MultiQC multiqc report.html Voir s√©quences dupliqu√©es FastQC (Overrepresented sequences) fastqc sample.fastq.gz Filtrer adaptateurs/rRNA Nettoyage des reads cutadapt, bbduk, SortMeRNA Aligner sur g√©nome D√©terminer l‚Äôorigine (biologique ou technique) bowtie2, STAR, bwa Estimer complexit√© de librairie Saturation / diversit√© preseq

Souhaites-tu que je t‚Äôaide √† faire l‚Äôun de ces diagnostics √©tape par √©tape avec tes fichiers ?

Merci pour la pr√©cision ! Le fait que la variabilit√© de duplication concerne le R2 contenant les barcodes (Split-seq) change compl√®tement l‚Äôinterpr√©tation ‚Äî et c‚Äôest attendu dans ce cas. Voici pourquoi :

‚∏ª

‚úÖ Pourquoi observe-t-on une forte duplication dans les reads R2 (barcodes) en Split-seq ?

üîπ 1. R2 ne refl√®te pas l‚ÄôARNm, mais les barcodes de marquage cellulaire

Dans Split-seq, le read 2 contient : ‚Ä¢ Les barcodes de cellule, de well, et parfois des UMI (unique molecular identifiers). ‚Ä¢ Ces s√©quences sont courtes et proviennent d‚Äôun nombre limit√© de combinaisons (des dizaines √† centaines de barcodes possibles).

üëâ Cela veut dire que le contenu du read 2 est volontairement redondant.

üîπ 2. R√©p√©tition intentionnelle de s√©quences dans R2

Exemple : ‚Ä¢ Si tu as 96 puits + 48 barcodes de round 2, tu n‚Äôauras que quelques centaines de combinaisons uniques dans R2. ‚Ä¢ Mais tu as des millions de lectures, donc chaque barcode appara√Æt des milliers de fois ‚Üí duplication √©lev√©e dans R2.

üîπ 3. Pas un probl√®me de qualit√©, mais une cons√©quence du protocole

C‚Äôest normal, attendu, et non probl√©matique du tout pour l‚Äôanalyse ‚Äî car ces duplications repr√©sentent des barcodes techniques, pas des artefacts de PCR ou de mauvaise pr√©paration de librairie.

‚∏ª

üìä Pourquoi cette variabilit√© entre √©chantillons R2 ?

La variabilit√© entre √©chantillons R2 peut s‚Äôexpliquer par :

Cause possible Explication üìà Nombre de cellules diff√©rentes Un √©chantillon avec moins de cellules aura plus de redondance de barcodes. üß¨ R√©partition in√©gale de barcodes Mauvais m√©lange ou √©tiquetage in√©gal lors des √©tapes de split (rounds de barcoding). üß™ Efficacit√© du reverse transcription ou capture ARN Peut biaiser la repr√©sentation de certains barcodes. üß´ Contamination crois√©e entre puits Peut aussi expliquer des duplications anormales.

‚∏ª

üß† √Ä retenir ‚Ä¢ ‚úÖ Duplication √©lev√©e dans R2 (barcodes Split-seq) est normale. ‚Ä¢ üß™ FastQC n‚Äôest pas con√ßu pour interpr√©ter ce type de donn√©es ‚Üí il est plus utile sur R1 (o√π se trouve le transcriptome). ‚Ä¢ ‚ùå Ne filtre surtout pas ces duplications sur R2. ‚Ä¢ ‚úîÔ∏è Continue l‚Äôanalyse avec des outils comme zUMIs, split-pipe, kb-python, ou le pipeline adapt√© √† ton protocole Split-seq.

‚∏ª

Souhaites-tu que je t‚Äôaide √† identifier automatiquement les barcodes valides ou √† pr√©parer un pipeline pour la phase de ‚Äúdemultiplexing‚Äù ?

Oui, exactement : si tu observes des √©chantillons R2 (barcodes) sans ou avec tr√®s peu de duplication, c‚Äôest potentiellement probl√©matique dans un protocole comme Split-seq. Voici pourquoi :

‚∏ª

‚ùå Peu de duplication dans R2 (barcodes) : signal d‚Äôalerte

Dans un bon √©chantillon de Split-seq : ‚Ä¢ Le R2 contient des barcodes techniques qui devraient √™tre fortement redondants. ‚Ä¢ Chaque combinaison de barcodes doit √™tre lue des milliers de fois (car chaque cellule donne lieu √† de nombreuses lectures avec le m√™me barcode).

Donc, si : ‚Ä¢ üìâ Tu as tr√®s peu de duplication dans R2, ‚Ä¢ Cela signifie probablement que les barcodes sont absents, mal lus ou trop diversifi√©s, ‚Ä¢ Ce qui peut rendre impossible le regroupement des lectures par cellule (la base du single-cell).

‚∏ª

üîç Causes possibles d‚Äôune faible duplication en R2

Cause Explication ‚ùå Probl√®me de lecture du R2 (s√©quen√ßage) Mauvaise qualit√© du read, s√©quence illisible, ou erreur de base-calling. ‚ùå Mauvais design ou synth√®se des barcodes Si les barcodes n‚Äôont pas √©t√© bien int√©gr√©s, ou si des erreurs ont √©t√© introduites (ex : oligo d√©grad√©). ‚ùå √âchec du marquage lors du split Si les cellules n‚Äôont pas bien √©t√© barcod√©es (erreur dans les rounds de split). ‚ùå Orientation incorrecte ou mauvais parsing Si l‚Äôoutil d‚Äôanalyse lit R2 sans trouver la s√©quence attendue (ex : motif de linker/barcode non d√©tect√©).

‚∏ª

‚úÖ Attendu : un pic de duplication dans R2

Dans des donn√©es Split-seq fonctionnelles, tu dois voir : ‚Ä¢ Une forte duplication dans les classes \>10, \>50, \>100, etc. dans R2. ‚Ä¢ Si un √©chantillon n‚Äôa pas cela, il peut √™tre non-exploitable ou √† v√©rifier de pr√®s.

‚∏ª

üß™ Que faire maintenant ? 1. Comparer les FastQC de tous les R2 entre √©chantillons pour voir s‚Äôil y a une vraie anomalie. 2. Regarder un √©chantillon de s√©quences R2 brutes (FASTQ) : ‚Ä¢ Est-ce que tu vois bien les motifs de barcodes ? ‚Ä¢ Est-ce qu‚Äôils sont bien positionn√©s et consistants ? 3. Utiliser un outil de parsing de barcodes (comme umi_tools extract ou splitseq-pipe) pour voir combien de barcodes valides sont retrouv√©s.

‚∏ª

Souhaites-tu que je t‚Äôaide √† √©crire un petit script pour explorer la diversit√© de barcodes dans les R2 d‚Äôun FASTQ ?

reception of the data -verif data quality

BARQC pour recuperer barcode , mieux que starsolo pour les barcodes verif contamination voir help curation des donn√©es

76 et 80 corr R2 bcp de duplication donc bien mais les deux autres pas √ßa donc bizarre

faire schema avec representation des barcodes

fig BARQC

fig profondeur de sequen√ßage am√©liore ou pas

------------------------------------------------------------------------

Bilan du 09/05/2025 - mis du temps pour la reception des donn√©es - au debut du stage pr√©-donn√©es mais je ne pouvais rien en faire du tout car pas tout les barcodes - avant fait biblio sur l'ANR, sujets de stage (contexte biologique), types d'analyses (seurat, scanpy, ...) et logiciels pour traiter les donn√©es - lecture des cours des M1 en single cell et la formation Norwich - test d'un pipeline (BacSC) - analyse de donn√©es d'autres articles (le probleme etait la dispo des donn√©es), preparation de script pour analyser les donn√©es - Appris √† utiliser le cluster, preparer les metadatas, - fait mon template quarto pour le rapport de stage - appris √† utiliser cursor - decouvert de pipelines Nextflow - construction d'un docker et devcontainer pour maximiser la reproductibilit√© (vraiment cool pour apr√®s ) - appris √† utiliser renv - appris quarto - appris renv - appris cursor, agent

-   reception des donn√©es le 25/04/2025
    -   Brute data : 230 go (no demultiplexing)
    -   Processed data : 150 go (demultiplexing)
        -   8 fastq files (R1 and R2)
        -   4 index for Novaseq (BC_0076, BC_0077, BC_0079, BC_0080)
            -   "1) BC_0076 (R1: 42.8GB, R2: 18.6GB)"
            -   "2) BC_0077 (R1: 21.3GB, R2: 9.6GB)"
            -   "3) BC_0079 (R1: 25.2GB, R2: 11.3GB)"
            -   "4) BC_0080 (R1: 26.6GB, R2: 11.6GB)"
    -   au debut : probleme de stockage des donn√©es sur le cluster pas assez de memoire pour les fichiers bruts et lancer les analyses
        -   remarque :
            -   index de poids variable (Go)
            -   sur leur graph deux points outliers non mentionn√©s dans leur doc
            -   pour le demultiplexing ont eu besoin des sequences compl√©mentaires finalement
-   d'abord j'ai fait un test STARsolo sur des donn√©es brutes d√©multiplex√©es mais non nettoy√©es
    -   detection des barcodes (80% des barcodes sont bien d√©tect√©s)
    -   mais les reads sont tr√®s bruit√©s et il y a des reads qui ne sont pas align√©s (tr√®s faible nombre dans la matrice)
    -   detection de beaucoup de cellules mais avec chacun peut de reads de g√®nes exprim√©s
    -   donc pas de r√©sultats satisfaisants
    -   aussi test seurat : voit conditions de stress moins de reads et plus DO augmente pareil
-   choix de nettoyer les donn√©es
    -   pour la suite des analyses, on a choisi de verifier la qualit√© des donn√©es avant de nettoyer les donn√©es pour avoir des reads de meilleure qualit√©
    -   pour cela on a fait un fastqc et un multiqc pour voir la qualit√© des donn√©es
        -   beaucoup d'adaptateurs sur R1 (contient l'insert)
            -   donc on a fait un nettoyage des donn√©es avec fastp pour enlever les adaptateurs (trimming)
            -   aussi on enl√®ve les polyG (polyG bias)
            -   beaucoup de duplication sur R2 (barcodes) mais seulement pour deux des quatre index
            -   c'est etrange car on devrait observer la meme chose pour les quatre index

![image](../figures/BC_0076_dupli_R2.png) =\> 76 et 80 corr R2 bcp de duplication donc bien mais les deux autres pas √ßa donc bizarre

aussi en R1 : bcp de duplication mais pas pour les quatre index

![image](../figures/BC_0076_overr_seq_R1.png) =\> beaucoup de s√©quences surrepr√©sent√©es (illumina adapter, ...)

![image](../figures/BC_0076_Adapt_R1.png) =\> beaucoup d'adaptateurs sur R1 (contient l'insert)

-   on a donc fait un nettoyage des donn√©es avec fastp pour enlever les adaptateurs

-   si jamais le cut ne marche pas,  essai de cut tr√®s court (74pb je crois ) pour ne pas avoir les sequence d'adaptateur pour un meilleur alignement 

-   qualit√© des donn√©es

    -   fastqc
    -   multiqc
    -   fastp
    -   BARQC
    -   contamination

lister les figures que je veux mettre dans le rapport

![image](../figures/final_libraries.png)

BC_0076 CAGATC
BC_0077 ACTTGA
BC_0078 TAGCTT
BC_0079 GGCTAC

j'ai recherch√© dans le  R1 contient l'insert et possiblement barcodes si taille petites
round 2 linker :  5' CCACAGTCTCAAGCACGTGGAT 3'
round 3 linker :  5' AGTCGTACGCCGATGCGAAACATCGGCCAC 3'

Truseq read 2 : 5' AGATCGGAAGAGCACACGTCTGAACTCCAGTCA 3'
Illumina P7 : 5' ATCTCGTATGCCGTCTTCTGCTTG 3'

l'index est ici normalement situ√© entre les deux sequence mais ici grace demultiplexage deja supprime 

nous on cherche plutot les barcodes dans le R2 : 
Truseq Read 2 :   3' TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG 5' 
donc la sequence reverse pour find :  5' GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT 3' => pas retrouve 

reverse de round 3 linker : 5'*GTGGCCGATGTTTCGCATCGGCGTACGACT* 3'
reverse de round 2 linker : 5'*ATCCACGTGCTTGAGACTGTGG* 3'

UMI (10bp) -round3 barcode (8pb)- linker_rd3 (30pb)- round 2 barcode (8pb) - linker_rd2 (22 pb) barcode rd1 (8pb) fait 86pb  au total 
ici bien BC_0076 car **CAGATC** issu du demultiplexage 
# exemple :

pour le R1 : insert (taille variable : 0pb √† 196 pb ) normalement 241 cycles mais 
du coup 76 pb la seqeunce qui suit 
*AATGATACGGCGACCACCGAGATCTACACT*AGATCGC*TCGTCGGCAGCGT*CAGATGTGTATAAGAGACAG  ...........
*Ilummina P5*                     truc     s5             ME                   cDNA

la plateforme a probablement deja trimm√© : AGATCGCTCGTCGGCAGCGTCAGATGTGTATAAGAGACAG en amont du cDNA qui fait 42 bp =>>> peut etre ils enl√®vent des sequences utile lorsque l'insert est petit, discuter avec eux 

@LH00611:18:225KMWLT1:2:1101:3219:1096 2:N:0:CAGATC                           
read 2 : 
5' TNTACGCCGAGTCTGTCA*GTGGCCGATGTTTCGCATCGGCGTACGACT*GACAGTGC*ATCCACGTGCTTGAGACTGTGG*TATAGTCGCTGAC 3'

vgoupille@genossh:/projects/ecogeno/DEV/2025_GoupilleValentin$ ./view_fastq_head.sh data/processed_data/unzipped_data/NTS-412_fastq/fastq/BC_0076_R1.fastq.gz 80
Showing first 80 lines of data/processed_data/unzipped_data/NTS-412_fastq/fastq/BC_0076_R1.fastq.gz:
----------------------------------------
@LH00611:18:225KMWLT1:2:1101:1111:1096 1:N:0:CAGATC
ANATCGAGTAGGACGGAACCCAC*CCACAGTCTCAAGCACGTGGAT*TTCAGCTC**AGTCGTACGCCGATGCGAAACATCGGCCACT**AGTTCCACATAAACACAAGATAGGAAGAGCACACGTCTGAACTCCAGTCACCAGATCATCTAGGGGGGGGGGGGGGGGTTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGG
+
I#IIII9II*IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9III9IIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIII9IIIIIIIIIIII9*III*9I*I*99*9**9***9*9***99999999IIIII9I9I99I9999III9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII#III
@LH00611:18:225KMWLT1:2:1101:1203:1096 1:N:0:CAGATC
GNAGTGGTATCAACGCAGAGTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGTGGCGAGCGAACGGGGGTCCGGGCG*CCACAGTCTCAAGCACGTGGAT*GTTCGCCTGTCGTACGCCGATGCTAAACATCGGCCACTCGNCGT
+
I#IIII9I9IIIIIIIIIII9IIII*IIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIIIIIIII*IIIIIII9IIIII9IIIII9I9I9IIII9*IIIIIIII9IIIIIIIIIIII99I*IIIIIIII99II99IIIIIIII9I9IIIIIII9III999IIII9III*I9II9**III9I9I9*9II*I9I99I99I9I9*9*II*I**9I9*I*9*9I9****#**9
@LH00611:18:225KMWLT1:2:1101:1277:1096 1:N:0:CAGATC
ANTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGTGGCGAGCGAACGGGGACTAGCCCTTCAGCTTCTTTGATTTTCGCGGCACGCTCTGGAAAGTGCGGCCATAGTGGGTGATCGCCCTGTACGCGAAAGGATCTTCGAAGTGAAATCGAGTAGGACGGAGCACGACTCTC*CCACAGTCTCAAGCACGTGGAT*TGAACTGGAGTCGTACGCCGATNCGA
+
I#I*IIIII9IIIIIIIIIIIIIIIIIIIIIIIIIII9II9IIIIIIIIII9IIII9IIIIIIIIIIII9II*I9IIIIII99I9IIIIIIIIIIII*IIII**I9IIII9*I9II9*9II**I*I99*999I9I9*9*99*9**II9999*9999I*9*9IIIII*III9IIIIIIII9IIII9I9I9I*I9I99*IIII9II*9*9I**I*II9*9999*I*III*9II*II9*I#**9
@LH00611:18:225KMWLT1:2:1101:1499:1096 1:N:0:CAGATC
GNGAATACGTTCCCGGGCCTTACACACACCGCCCGTCACACCATGGGAGTGGGTTGCACCAGAAGTAGCTAGTCTAACCTTCGGGAGGACGGTTACCACGGTGTGATTCATGACTGGGGTGAAGTCGTAACAAGGCATAACCGTA*CCACAGTCTCAAGCACGTGGAT*ACAGTGGTATCAACGCAGAGTGGATGGAATGAT**AGTCGTACGCCGATGCGAAACATCGGCCAC**TCAGGAGNTGA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9*IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9III9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9II#III
@LH00611:18:225KMWLT1:2:1101:1703:1096 1:N:0:CAGATC
ANCAGTGGTATCAACGCAGAGTGAATGGGGGTCAAGTGAAGAAGCGCATACGGTGGATGCCTTGGCAGTCAGAGGCGATGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCGGAGATGTCTGCAGGGGGAACCCAC*CCACAGTCTCAAGCACGTGGAT*TGTGGTTGATTCGTACGCCGATGCGAAACATCGGCCACTGTACCTTCCACACACTTAGA
+
I#IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9III9IIIIIIIIII9
@LH00611:18:225KMWLT1:2:1101:1740:1096 1:N:0:CAGATC
GNTGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCGGAGATGTCTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGTGGCGAGCGAACGGGGACTAGCCCTTAAGCTTCTTTGATTTTG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIII*II9IIIIIII*IIII*
@LH00611:18:225KMWLT1:2:1101:1758:1096 1:N:0:CAGATC
CNAAGTTTAAGGTGGTAGGCTGAATCTTAGGTAAATCCGGGATTCTAAGGCCGAGAGCTGATGACGAGTTACCCTTTGGGTGACGAAGTGGTTGATGCCATGCTTCCAAAAAGGCTTCTAAGCTTCAGGCCCCAAGCA*CCACAGTCTCAAGCACGTGGAT*TAGTCTTGAGTCGTACGCCGATGCGAAACATCGGCACTCTCGGTTCAAAAAAAGTAGCTCGGAAGAGCACCCTTCTGAACT   
+
9#9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIII9II99IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9III9III9IIIIIIIIIIIIIIIII9IIIIIIIIIIIIIII9IIIIIIIIII9I9II99IIIII9IIII99IIIIIIIIIIIIIIIIII*9IIIIII*III**9*9I99*II*
@LH00611:18:225KMWLT1:2:1101:1777:1096 1:N:0:CAGATC
ANGCAGTGGTATCAACGCAGAGTGAATGGGAAAGACCCCGTGAACCTTTACTATAGCTTTGCACTGGACTTTGAATTTGCTTGTGTAGGATAGGTGGGAGGCTTTGAAGCGTGGACGCCAGTTCGCGTGGAGCCATCCTTGAAATACCACCCTGGCAACTTTGAGGTTCTAACTCAGGTCCGTTATCCAGATCGGGACAG*CCACAGTCTCAAGCACGTGGAT*TCTCACGGAGTCGTACGCC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1814:1096 1:N:0:CAGATC
CNTTGATCCGGAGATGTCTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGG*AAAAAAAAAAAAAAA*GAACCCAC*CCACAGTCTCAAGCACGTGGAT*TGTGAAGA**AGTCGTACGCCGATGCGAAACATCGGCCAC**TGTTCTCCTGGACTATTGAGATCGGAAGAGCACACGTCTG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIII9III99IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIII*9II9III*IIII9IIIII99I9II99I9
@LH00611:18:225KMWLT1:2:1101:1832:1096 1:N:0:CAGATC
TNGTTGTCCAAGTTTAAGGTGGTAGGCTGGAATCTTAGGTAAATCCGGGATTCTAAGGCCGAGAGCTGATGACGAGTTACCCTTTGGGTGACGAAGTGGTTGATGCCATGCTTCCAAGAAAAGCTTCTAAGCTTCAGGTAACCAAGTAACCGTA*CCACAGTCTCAAGCACGTGGAT*TGACAGACAGTCGTACGCGATGCGAAACATCGGCCACAGAGTGGTATAAAAACATAGATCGGAAG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2072:1096 1:N:0:CAGATC
GNGTGAATGGGTGTCG**AGTCGTACGCCGATGCGAAACATCGGCCAC**TGCTGATAAGCCACACAC**AGATCGGAAGAGCACACGTCTGAACTCCAGTCA**CCAGATCATCTAGGGGGGGGGGGGTGGTTTGGGAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9*IIII9**99***********9*****99999*9999999I9III9I9I999IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2165:1096 1:N:0:CAGATC
ANCGCATACGTCCTACGGGAGAAAGCAGGGGACCTTCGGGCCTTGCGCTATCAGATGAGCCTAGGTCGGATTAGCTAGTTGGTGAGGTAATGGCTCACCAAGGCGACGATCCGTAACTGGTCTGAGAGGTAAGACAGTGC*CCACAGTCTCAAGCACGTGGAT*ATCACGTT**AGTCGTACGCCGATGCGAAACATCGGCCAC**GATCTCTTCTAGTAATTTAGATCGGAAGAGCACACGTCTGA
# par exemple r1 contient un insert assez court : ANCGCATACGTCCTACGGGAGAAAGCAGGGGACCTTCGGGCCTTGCGCTATCAGATGAGCCTAGGTCGGATTAGCTAGTTGGTGAGGTAATGGCTCACCAAGGCGACGATCCGTAACTGGTCTGAGAGGTAAGACAGTGC (132pb -8pb (barcode round1) = 124pb donc on arrive a retrouver le barcodes dans l'autre sens) moi je vais vouloir trimm√© ce qui suis alors pour l'alignement 

# ici par exemple contient round 2 linker et round 3 linker : donc barcode round 2 entre les deux (8pb) , avant round 2 linker on a normalement barcode round 1 (8pb)
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2220:1096 1:N:0:CAGATC
GNATCAACGCAGAGTGATCGGAAGAGCACACGTCTGAACTCCAGTCACCAGATCATCTAGGGGGGGGGGGTGTTTTTTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII99*I9I9I9999***********9***999999999999999I9I9III99III9III9II9I9IIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2442:1096 1:N:0:CAGATC
GNTATCAACGCAGAGTGAATGGGGGTCAAGTGAAGAAGCGCATACGGTGGATGCCTTGGCAGTCAGAGGCGATGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCGGAGATGTCTGAATGGGGGACTAATTTC*CCACAGTCTCAAGCACGTGGAT*TCCAGTCG**AGTCGTACGCCGATGCGAAACATCGGCCAC**TGCATAGTGTGGGGCAGCAGNTCG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII#III
@LH00611:18:225KMWLT1:2:1101:2535:1096 1:N:0:CAGATC
CNCCCTTTAAAGAAAGCGTAATAGCTCACTAGTCGAGTCGGCCTGCGCGGAAGATGTAACGGGGCTCAAACCATACACCGAAGCTACGGGTATCACGTAAGTGATGCGGTAGAGGAGCGTTCTGTAAGCCTGTGAAGGTGAGTTGAGAAGCTTGCTGGAGGTATCAGAAGTGCGTCGGGACAGCCACCGTCTCAAGCACGTGGATCTTGTACTATTCGTACGCCGATGCGAAGCATCNGCC
+
I#IIIIIII*III9IIIIIIIII9IIIII*IIIII9IIIIIIIIII9IIII9I*I9IIIIII9IIIIIIIII9IIIII9IIIIIIIIIIIIIII99I9IIIIIIIIIIIIIIIIIIIII9III9IIIII*IIIIIII*IIIIIIIIIIIIIIII9IIII99III9I*II*III9IIII9IIII9II9*IIII9I9*9I9*I*9*I99I*I99*9*9I99II*99II*99*99**I9*#9I9
@LH00611:18:225KMWLT1:2:1101:2997:1096 1:N:0:CAGATC
GNCATGCCGCGTGTGTGAAGAAGGTCTTCGGATTGTAAAGCACCTTAAGTTGGGAGGAAGGGCATTAACCTAATACGTTAGTGTTTTGACGTTACCGACAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCGCGTAGGTGGTTCGTTAAGTTGGATGTAAATCCCCGGGCTCAACCTGGGAACNGCA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII*IIIIIIIIIIIIIIIIIIIIIIIII9II9IIIIIIIIIIIIIIIIIIIIIIIIIII9II9IIII#III
@LH00611:18:225KMWLT1:2:1101:3034:1096 1:N:0:CAGATC
CNTGGACTGATACTGACACTGAGGTGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCAACTAGCCGTTGGGAGCCTTGAGCTCTTAGTGGCGCAGCTAACGCATTAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTAAAACCCAAAAAAAAAAAAAATAGGGTAG*CCACAGTCTCAAGCACGTGGAT*GAGGATGGAGTCGTACGCNGAT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIII*IIIIIIIII9IIIIIII9IIIII9IIIII9IIIIIIIIIIIIIIIIIIIII99IIIIIIIIIIIII9I9III#*II
@LH00611:18:225KMWLT1:2:1101:3052:1096 1:N:0:CAGATC
GNAGGACGGAGCACTAATTTC*CCACAGTCTCAAGCACGTGGAT*GTTAGCCT**AGTCGTACGCCGATGCGAAACATCGGCCAC**TCGAGCGTCAATGCCCTCAGATCGGAAGAGCACACGTCTGAACTCCAGTAAACAGATCATCTATGGGGTGCTGTTTTTTTTGGTAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGAGGGGGAGGGGGGGGNGGG
+
I#9II99I99I9999IIII9IIIII99IIIII9IIIIIIII*9IIII99IIIIIIII*IIII9IIIIIIIII99IIII99III9I9IIIIIIIIIIIIIIII9*I99I9IIIIIII999I9III*I**I9**9**9999999*9*9***********9*9**9***999999*999****999**99*9**99***99999*99*99****99****99999*99*99*9****999#9*9
@LH00611:18:225KMWLT1:2:1101:3219:1096 1:N:0:CAGATC
GNAGTGAAATCGAGTAGGACGGAGCACGAGAAACTTTGTCTGAATATGGGGGGACCATCCTCCAAGGCTAAATACTACTGACTGACCGATAGTGAACTAGTACCGTGAGGGAAAGGCGAAAAGAACCCCTGAGAGGGGAGTGAAATAGATCCTGAAACCGTATGCGTACAAGCAGTGGGAGCCCACTTTGTTGGGTGACTGCGTACCTTTTGTATAATGGGTCAGCGACTATACCACAGTC
+
I#IIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIII9II9IIII
@LH00611:18:225KMWLT1:2:1101:3293:1096 1:N:0:CAGATC
ANGCAGTGGTATCAACGCAGAGTGAATGGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCAACTAGCCGTTGGGAGCCTTGAGCTCTTAGTGGCGCAGCTAACGCATTAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTAAAACTCAAATGAATTGACGGGGTCCCTTAG*CCACAGTCTCAAGCACGTGGAT*TCGAGCGT**AGTCGTACGCCGATGCGAAACATCGGCCAC**T
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIII9IIIII9IIIIIIIIIIIIIIIII9IIIIII





vgoupille@genossh:/projects/ecogeno/DEV/2025_GoupilleValentin$ ./view_fastq_head.sh data/processed_data/unzipped_data/NTS-412_fastq/fastq/BC_0076_R2.fastq.gz 80
Showing first 80 lines of data/processed_data/unzipped_data/NTS-412_fastq/fastq/BC_0076_R2.fastq.gz:
----------------------------------------
@LH00611:18:225KMWLT1:2:1101:1111:1096 2:N:0:CAGATC
TNTGTTTCCTTTGAACCCATGGCCCACGTTTCGCCCCCGCGTCCCACCTATCCGACCCCCCCCCCCTTTACACCGCTGGTTGGTTCCCTCC
+
I#I*9II9**9*9***9*****99**9******99*99*9***9**999**9**9*9999*99******9**9***9*9**9*99*9*99*
@LH00611:18:225KMWLT1:2:1101:1203:1096 2:N:0:CAGATC
TNGGATTAAACACTTCGAGTGGCCGATGTTTCGCATCGGCGTACGACAGGCTAAC*ATCCACGTGCTTGAGACTGTGG*CGCCCGGACCCCCG
+
9#IIIIII*III*IIIIIIIIIIII9IIIIIIIIIIIIIIIIIII*II9III99I9IIIIIIIII9IIIIIIIIIIIIII*III*IIIIII
@LH00611:18:225KMWLT1:2:1101:1277:1096 2:N:0:CAGATC
TNCCCGTGTGTGGCTTCA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CCAGTTCA*ATCCACGTGCTTGAGACTGTGG*TATAGTCGTGCTC
+
I#IIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIII
@LH00611:18:225KMWLT1:2:1101:1499:1096 2:N:0:CAGATC
TNTCTTTTCACCTCCTGA*GTGGCCGATGTTTCGCATCGGCGTACGACT*ATCATTCCATCCACTCTGCGTTGATACCACTGTATCCACGTGC
+
I#IIIIIIIIIIII9III9IIIIII*I9IIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1703:1096 2:N:0:CAGATC
ANGTGTGTGGAAGGTACAGTGGCCGATGTTTCGCATCGGCGTACGAATCAACCACA*ATCCACGTGCTTGAGACTGTGG*GTGGGTTCCCCCT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1740:1096 2:N:0:CAGATC
ANAGTGCTTGACAGATTC*GTGGCCGATGTTTCGCATCGGCGTACGACT*GTGTTCTA*ATCCACGTGCTTGAGACTGTGG*GGGTAGCGTTTTT
+
I#IIIII9IIIIIIIIIIIIIIIII*IIIIIIII*IIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII*IIII
@LH00611:18:225KMWLT1:2:1101:1758:1096 2:N:0:CAGATC
ANTTTTTTTGAACCGAGAGTGCCGATGTTTCGCATCGGCGTACGACTCAAGACTA*ATCCACGTGCTTGAGACTGTGG*TGCTTGGGGCCTGA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9II*IIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1777:1096 2:N:0:CAGATC
TNTTATTCTTGAGCTGAA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CCGTGAGA*ATCCACGTGCTTGAGACTGTGG*CTGTCCCGATCTG
+
I#IIIIIIIIIIIIIIII99*IIII*IIIIIIIIIIIIIIII*II9IIIIIIIIIIIIIIIIIIIIIIII*IIIIIIIIIIIII9IIIIII
@LH00611:18:225KMWLT1:2:1101:1814:1096 2:N:0:CAGATC
CNATAGTCCAGGAGAACA*GTGGCCGATGTTTCGCATCGGCGTACGACT*TCTTCACA*ATCCACGTGCTTGAGACTGTGG*GTGGGTTCTTTTT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1832:1096 2:N:0:CAGATC
ANGTTTTTATACCACTCTGTGGCCGATGTTTCGCATCGCGTACGACTGTCTGTCA*ATCCACGTGCTTGAGACTGTGG*TACGGTTACTTGGT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2072:1096 2:N:0:CAGATC
GNGTGTGGCTTATCAGCA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CGACACCCATTCACTCAGATCGGAAGAGCGTCGTGTAGGGAAA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII**III*II
@LH00611:18:225KMWLT1:2:1101:2165:1096 2:N:0:CAGATC
ANATTACTAGAAGAGATC*GTGGCCGATGTTTCGCATCGGCGTACGACT*AACGTGAT*ATCCACGTGCTTGAGACTGTGG*GCACTGTCTTACC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9I9IIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2220:1096 2:N:0:CAGATC
GNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGAGGTCCCATCTACCGCCTCACACCACCC
+
I#IIIIIIIIIIIIIIIIIIIIIII9I9IIII*IIII99IIIII*I9II9*9I999IIII*9***9*9*******9***9******9999*
@LH00611:18:225KMWLT1:2:1101:2442:1096 2:N:0:CAGATC
GNTGCCCCACACTATGCA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CGACTGGA*ATCCACGTGCTTGAGACTGTGG*GAAATTAGTCCCC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2535:1096 2:N:0:CAGATC
GNGGGGAGAGGTGTTCTA*GTGGCCGATGTTTCGCATCGGCGTACGACT*AGTACAAG*ATCCACGTGCTTGAGACTGTGG*CTGTCCCGACGCA
+
I#*******9999*9**9I9II9*9*9II*9*9*9**9I*I99999999*99999I999I9IIII9IIIIIIII9I9IIIIII9IIIIIII
@LH00611:18:225KMWLT1:2:1101:2997:1096 2:N:0:CAGATC
GNTCGCTTCGGGAGAACA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CCAGTTCA*ATCCACGTGCTTGAGACTGTGG*TATAGTCGTCTTC
+
I#IIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3034:1096 2:N:0:CAGATC
CNTATAAGTTTCCGTCTA*GTGGCCGATGTTTCGCATCGGCGTACGACT*CCATCCTC*ATCCACGTGCTTGAGACTGTGG*CTACCCTATTTTT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3052:1096 2:N:0:CAGATC
GNGGGGGTTGAGGCTTGA*GTGGCCGATGTTTCGCATCGGCGTACGACT*AGTCTAAC*ATCCACGTGCTTGAGACTGTGG*GAAATTAGTGCTC
+
I#III****9**9***99I9II*99*999I9*II*IIIIII*III*III9*III9IIII99I*III9*9*9*99IIIIII9I99**99I*I
@LH00611:18:225KMWLT1:2:1101:3219:1096 2:N:0:CAGATC
TNTACGCCGAGTCTGTCA*GTGGCCGATGTTTCGCATCGGCGTACGACT*GACAGTGC*ATCCACGTGCTTGAGACTGTGG*TATAGTCGCTGAC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3293:1096 2:N:0:CAGATC
TNGTCGTGCTCAAGACTA*GTGGCCGATGTTTCGCATCGGCGTACGACT*ACGCTCGA*ATCCACGTGCTTGAGACTGTGG*CTAAGGGACCCCG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIII9I9IIIIIIIIII*IIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIII9IIIIIII




j'analyse la structure des donn√©es fastq : 

je veux trimmer les sequences r1 qui contiennent : 
NNNNNNNNCCACAGTCTCAAGCACGTGGATNNNNNNNNAGTCGTACGCCGATGCGAAACATCGGCCACNNNNNNNNNNNNNNNNNNAGATCGGAAGAGCACACGTCTGAACTCCAGTCACNNNNNNATCTCGTATGCCGTCTTCTGCTTG -3'

la sequence (insert d'interet est situ√© avant 5' NNNNNNNNCCACAGTCTCAAGCACGTGGAT 3'  correspond au 8pb rd1 barcode suivie de Round2 linker 

mais si encore plus mauvais le R1 peut contenir  seulement linker round3 (AGTCGTACGCCGATGCGAAACATCGGCCAC) ou meme encore plus loin AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC qui est le truseq read 2 et si encore plus loin Illumina P7  (ATCTCGTATGCCGTCTTCTGCTTG)



-Faire un subset : de fatsq (voir sur RNAseq Nextflow )

- Novaseq pair-end 
- R2 contient les barcodes
- R1 contient l'insert (si long) et possiblement barcode et adptateur si insert court ou pas existe  (erreur)


-cut adapt sur R1 

Read : AGCTTAGGCCACAGTCTCAAGCACGTGGATGTTTGA...
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò motif
             ‚Üì
        on supprime √† partir de l√†

CCACAGTCTCAAGCACGTGGAT est le linker round 2 , juste avant 8pb barcide round 1  et encore avant le cDNA 


R√©sultat : AGCTTAGG
cutadapt \
  -g 'NNNNNNNNNNNNCCACAGTCTCAAGCACGTGGAT' \
  --action=trim \
  -o R1_trimmed.fastq.gz \
  -p R2_untouched.fastq.gz \
  R1.fastq.gz R2.fastq.gz \
  > cutadapt_log.txt




  üéØ Objectif final :
	1.	D√©tecter le motif principal :
CCACAGTCTCAAGCACGTGGAT
‚Üí Supprimer 8 bases en amont du motif et tout ce qui suit.
	2.	Si ce motif n‚Äôest pas trouv√©, chercher un second motif alternatif :
AGTCGTACGCCGATGCGAAACATCGGCCAC
‚Üí Supprimer 38 bases en amont de ce second motif et tout ce qui suit.

 3. Si ce motif n‚Äôest pas trouv√©, chercher un troisi√®me  motif alternatif AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC	86 bases en amont	Supprimer ces 86 bases + tout ce qui suit





‚∏ª

üîÅ R√©sum√© des 3 r√®gles de trimming sur R1 uniquement :

Priorit√©	Motif √† d√©tecter	Position de coupe	Action
1	CCACAGTCTCAAGCACGTGGAT	8 bases en amont	Supprimer ces 8 bases + tout ce qui suit
2	AGTCGTACGCCGATGCGAAACATCGGCCAC	38 bases en amont	Supprimer ces 38 bases + tout ce qui suit
3	AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC	86 bases en amont	Supprimer ces 86 bases + tout ce qui suit
‚àÖ	Aucun motif d√©tect√©	Garder read entier	


‚∏ª

‚úÖ Script final mis √† jour avec les 3 r√®gles + synchro R2

Voici le script complet en Python :

from Bio import SeqIO
import gzip

# === PARAM√àTRES ===
input_R1 = "R1.fastq.gz"
input_R2 = "R2.fastq.gz"
output_R1 = "R1_trimmed.fastq.gz"
output_R2 = "R2_trimmed.fastq.gz"

motifs = [
    ("CCACAGTCTCAAGCACGTGGAT", 8),
    ("AGTCGTACGCCGATGCGAAACATCGGCCAC", 38),
    ("AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC", 86)
]

# === LECTURE SYNCHRONIS√âE ===
open_in = lambda f: gzip.open(f, "rt") if f.endswith(".gz") else open(f, "r")
open_out = lambda f: gzip.open(f, "wt") if f.endswith(".gz") else open(f, "w")

with open_in(input_R1) as handle_R1, open_in(input_R2) as handle_R2, \
     open_out(output_R1) as out_R1, open_out(output_R2) as out_R2:

    for rec1, rec2 in zip(SeqIO.parse(handle_R1, "fastq"), SeqIO.parse(handle_R2, "fastq")):
        seq = str(rec1.seq)
        cut = None

        for motif, offset in motifs:
            if motif in seq:
                i = seq.find(motif)
                cut = max(i - offset, 0)
                break  # d√®s qu'un motif est d√©tect√©, on s'arr√™te

        if cut is not None:
            rec1.seq = rec1.seq[:cut]
            rec1.letter_annotations["phred_quality"] = rec1.letter_annotations["phred_quality"][:cut]

        # √âcrire les deux reads seulement si R1 est encore assez long
        if len(rec1.seq) >= 20:
            SeqIO.write(rec1, out_R1, "fastq")
            SeqIO.write(rec2, out_R2, "fastq")


‚∏ª

üì¶ Ex√©cution
	‚Ä¢	Assure-toi d‚Äôavoir install√© :

pip install biopython

	‚Ä¢	Lance le script :

python trim_paired_custom.py


‚∏ª










Parfait Valentin‚ÄØ! Voici la version compl√®te et robuste de ton script, mise √† jour pour permettre la d√©tection avec erreurs (fuzzy matching) sur R1 uniquement, tout en gardant la synchronisation avec R2. üß¨üîß

‚∏ª

‚úÖ Objectif :
	‚Ä¢	Autoriser jusqu‚Äô√† 1 erreur (substitution/insertion/d√©l√©tion) par d√©faut.
	‚Ä¢	Appliquer les r√®gles de trimming par priorit√©.
	‚Ä¢	Garder la synchronisation des reads R1/R2.
	‚Ä¢	Ne garder que les reads R1 > 20 nt apr√®s trimming.

‚∏ª

üìú Script trim_r1_fuzzy.py

from Bio import SeqIO
import gzip
import regex as re

# === PARAM√àTRES ===
input_R1 = "R1.fastq.gz"
input_R2 = "R2.fastq.gz"
output_R1 = "R1_trimmed.fastq.gz"
output_R2 = "R2_trimmed.fastq.gz"

# Liste des motifs avec leur offset (bases √† supprimer avant le motif)
motifs = [
    ("CCACAGTCTCAAGCACGTGGAT", 8),
    ("AGTCGTACGCCGATGCGAAACATCGGCCAC", 38),
    ("AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC", 86)
]

# Nombre maximal d'erreurs autoris√©es (substitution/insertion/d√©l√©tion)
MAX_ERRORS = 1

def find_approx(seq, motif, max_errors):
    """Cherche un motif avec un nombre maximum d'erreurs."""
    match = re.search(f'({motif}){{e<={max_errors}}}', seq)
    return match.start() if match else None

# === GESTION DES FICHIERS COMPRESS√âS ===
open_in = lambda f: gzip.open(f, "rt") if f.endswith(".gz") else open(f, "r")
open_out = lambda f: gzip.open(f, "wt") if f.endswith(".gz") else open(f, "w")

# === TRAITEMENT PAIR√â (R1 seulement modifi√©) ===
with open_in(input_R1) as handle_R1, open_in(input_R2) as handle_R2, \
     open_out(output_R1) as out_R1, open_out(output_R2) as out_R2:

    for rec1, rec2 in zip(SeqIO.parse(handle_R1, "fastq"), SeqIO.parse(handle_R2, "fastq")):
        seq = str(rec1.seq)
        cut = None

        for motif, offset in motifs:
            pos = find_approx(seq, motif, MAX_ERRORS)
            if pos is not None:
                cut = max(pos - offset, 0)
                break  # On applique la 1re r√®gle qui match

        if cut is not None:
            rec1.seq = rec1.seq[:cut]
            rec1.letter_annotations["phred_quality"] = rec1.letter_annotations["phred_quality"][:cut]

        # On ne garde les reads que si R1 est encore assez long
        if len(rec1.seq) >= 20:
            SeqIO.write(rec1, out_R1, "fastq")
            SeqIO.write(rec2, out_R2, "fastq")


‚∏ª

üöÄ Instructions
	1.	Installe les d√©pendances :

pip install biopython regex

	2.	Lance le script avec :

python trim_r1_fuzzy.py

	3.	R√©sultat :

	‚Ä¢	R1_trimmed.fastq.gz contient les R1 coup√©s selon le motif trouv√© (avec erreurs autoris√©es).
	‚Ä¢	R2_trimmed.fastq.gz garde les R2 synchronis√©s (inchang√©s).

‚∏ª

üß™ Optionnel

Souhaites-tu :
	‚Ä¢	Un param√®tre par motif pour ajuster les erreurs ?
	‚Ä¢	Un fichier log avec statistiques des motifs trouv√©s ?
	‚Ä¢	Une version Snakemake ou bash ?

Je peux te l‚Äôajouter selon ton workflow.










Parfait, Valentin ! Voici une version mise √† jour de ton script, o√π :

‚∏ª

‚úÖ Nouveaut√© :

1. Si le read R1 contient une queue polyA (>=15 A cons√©cutifs) ‚Üí on coupe √† l‚Äôamont de cette queue, et on supprime le reste du read (comme un hard clipping).
2. Sinon, on applique ensuite les r√®gles pr√©c√©dentes (avec erreurs autoris√©es sur motifs).

‚∏ª

üß¨ Nouveau comportement :

Priorit√©	R√®gle appliqu√©e sur R1	Action
1Ô∏è‚É£	PolyA (>=15 A) d√©tect√©	Couper √† l‚Äôamont de la queue + supprimer tout le reste
2Ô∏è‚É£	Motif CCACAG... d√©tect√© avec ‚â§1 erreur	Supprimer 8 nt en amont
3Ô∏è‚É£	Motif AGTCGTAC... d√©tect√© avec ‚â§1 erreur	Supprimer 38 nt en amont
4Ô∏è‚É£	Motif AGATCGGAAG... d√©tect√© avec ‚â§1 erreur	Supprimer 86 nt en amont


‚∏ª

üîß Script : trim_r1_polyA_then_motifs.py

from Bio import SeqIO
import gzip
import regex as re

# === PARAM√àTRES ===
input_R1 = "R1.fastq.gz"
input_R2 = "R2.fastq.gz"
output_R1 = "R1_trimmed.fastq.gz"
output_R2 = "R2_trimmed.fastq.gz"

# Motifs personnalis√©s √† d√©tecter avec leur offset
motifs = [
    ("CCACAGTCTCAAGCACGTGGAT", 8),
    ("AGTCGTACGCCGATGCGAAACATCGGCCAC", 38),
    ("AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC", 86)
]

MAX_ERRORS = 1  # tol√©rance d‚Äôerreurs

def find_approx(seq, motif, max_errors):
    match = re.search(f"({motif}){{e<={max_errors}}}", seq)
    return match.start() if match else None

def find_polyA(seq, min_len=15):
    match = re.search(f"A{{{min_len},}}", seq)
    return match.start() if match else None

open_in = lambda f: gzip.open(f, "rt") if f.endswith(".gz") else open(f, "r")
open_out = lambda f: gzip.open(f, "wt") if f.endswith(".gz") else open(f, "w")

with open_in(input_R1) as handle_R1, open_in(input_R2) as handle_R2, \
     open_out(output_R1) as out_R1, open_out(output_R2) as out_R2:

    for rec1, rec2 in zip(SeqIO.parse(handle_R1, "fastq"), SeqIO.parse(handle_R2, "fastq")):
        seq = str(rec1.seq)
        cut = None

        # Priorit√© 1 : PolyA
        polyA_pos = find_polyA(seq, min_len=15)
        if polyA_pos is not None:
            cut = polyA_pos  # on coupe juste avant la queue polyA

        else:
            # Sinon : motifs avec erreurs
            for motif, offset in motifs:
                pos = find_approx(seq, motif, MAX_ERRORS)
                if pos is not None:
                    cut = max(pos - offset, 0)
                    break

        if cut is not None:
            rec1.seq = rec1.seq[:cut]
            rec1.letter_annotations["phred_quality"] = rec1.letter_annotations["phred_quality"][:cut]

        # Ne garder que les s√©quences R1 >= 20 nt
        if len(rec1.seq) >= 20:
            SeqIO.write(rec1, out_R1, "fastq")
            SeqIO.write(rec2, out_R2, "fastq")


‚∏ª

üìå R√©sum√©
	‚Ä¢	PolyA >=15 ‚Üí prioritaire sur tous les autres motifs.
	‚Ä¢	Si aucun motif trouv√©, le read est conserv√© tel quel (si longueur suffisante).
	‚Ä¢	Synchronisation avec R2 garantie.

‚∏ª


deux possibilit√© soit random hexamer ou bien polyA pour capturer le plus de reads possible 

XXX...XXX(pA)
XXX...XXX (random hexamer)
    cDNA 

je peux modifier la regle pour supprimer les random hexamer et polyA 
    - si je considere -15 : alors ce supprime aussi bien polyA que random hexamer mais perd 9pb inutilement 


je vais utiliser cette approche pour commencer :pas de biais alignement entre les deux aux moisn 


D‚Äôaccord, Valentin ! Voici une version finale du script qui inclut :
	1.	Le trimming de 15 bases avant chaque motif (comme tu l‚Äôas demand√©).
	2.	L‚Äôajout d‚Äôun log pour suivre les statistiques sur les motifs d√©tect√©s et les trims effectu√©s.

‚∏ª

‚úÖ Ce que fait le script :
	1.	PolyA (>=15 A) : Si trouv√©, on coupe la s√©quence avant la queue polyA et on supprime tout apr√®s.
	2.	Autres motifs : Si un motif est trouv√©, on coupe 15 bases avant le motif.
	3.	Statistiques : Un fichier log.txt sera g√©n√©r√©, contenant des informations sur le nombre de reads trait√©s, le nombre de trims effectu√©s, et les motifs d√©tect√©s.

‚∏ª

üìú Script : trim_r1_with_log.py

from Bio import SeqIO
import gzip
import regex as re

# === PARAM√àTRES ===
input_R1 = "R1.fastq.gz"
input_R2 = "R2.fastq.gz"
output_R1 = "R1_trimmed.fastq.gz"
output_R2 = "R2_trimmed.fastq.gz"
log_file = "trim_log.txt"

# Liste des motifs avec leur offset (15 bases avant le motif)
motifs = [
    ("CCACAGTCTCAAGCACGTGGAT", 23),
    ("AGTCGTACGCCGATGCGAAACATCGGCCAC", 53),
    ("AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC", 101)
]

MAX_ERRORS = 1  # tol√©rance d‚Äôerreurs

def find_approx(seq, motif, max_errors):
    match = re.search(f"({motif}){{e<={max_errors}}}", seq)
    return match.start() if match else None

def find_polyA(seq, min_len=15):
    match = re.search(f"A{{{min_len},}}", seq)
    return match.start() if match else None

open_in = lambda f: gzip.open(f, "rt") if f.endswith(".gz") else open(f, "r")
open_out = lambda f: gzip.open(f, "wt") if f.endswith(".gz") else open(f, "w")

# === VARIABLES LOG ===
log_stats = {
    "total_reads": 0,
    "trimmed_reads": 0,
    "polyA_trimmed": 0,
    "motif_trimmed": {motif[0]: 0 for motif in motifs}
}

# === TRAITEMENT ===
with open_in(input_R1) as handle_R1, open_in(input_R2) as handle_R2, \
     open_out(output_R1) as out_R1, open_out(output_R2) as out_R2, \
     open(log_file, "w") as log:

    for rec1, rec2 in zip(SeqIO.parse(handle_R1, "fastq"), SeqIO.parse(handle_R2, "fastq")):
        seq = str(rec1.seq)
        cut = None

        log_stats["total_reads"] += 1  # Incr√©mente le compteur de reads trait√©s

        # Priorit√© 1 : D√©tecter PolyA (>=15 A)
        polyA_pos = find_polyA(seq, min_len=15)
        if polyA_pos is not None:
            cut = polyA_pos  # On coupe avant la queue polyA
            log_stats["polyA_trimmed"] += 1
            log.write(f"Read {rec1.id}: PolyA found at position {polyA_pos}, trimmed.\n")
        else:
            # Priorit√© 2 : Chercher motifs avec erreurs
            for motif, offset in motifs:
                pos = find_approx(seq, motif, MAX_ERRORS)
                if pos is not None:
                    cut = max(pos - offset, 0)
                    log_stats["motif_trimmed"][motif] += 1
                    log.write(f"Read {rec1.id}: Motif '{motif}' found at position {pos}, trimmed {offset} bases before.\n")
                    break

        if cut is not None:
            rec1.seq = rec1.seq[:cut]
            rec1.letter_annotations["phred_quality"] = rec1.letter_annotations["phred_quality"][:cut]

        # Ne garder que les s√©quences R1 >= 20 nt
        if len(rec1.seq) >= 20:
            SeqIO.write(rec1, out_R1, "fastq")
            SeqIO.write(rec2, out_R2, "fastq")
            log_stats["trimmed_reads"] += 1

    # === LOG STATISTIQUES ===
    log.write("\n=== STATISTIQUES ===\n")
    log.write(f"Total reads processed: {log_stats['total_reads']}\n")
    log.write(f"Total reads trimmed: {log_stats['trimmed_reads']}\n")
    log.write(f"Total PolyA trims: {log_stats['polyA_trimmed']}\n")
    for motif, count in log_stats["motif_trimmed"].items():
        log.write(f"Motif '{motif}' trims: {count}\n")


‚∏ª

üîß Instructions pour l‚Äôutilisation :
	1.	Installer les d√©pendances :

pip install biopython regex

	2.	Ex√©cuter le script :

python trim_r1_with_log.py

	3.	R√©sultats :
	‚Ä¢	Le fichier R1_trimmed.fastq.gz contient les s√©quences R1 apr√®s trimming.
	‚Ä¢	Le fichier R2_trimmed.fastq.gz reste synchronis√© avec R1.
	‚Ä¢	Le fichier trim_log.txt contient un rapport d√©taill√© avec des statistiques sur les motifs d√©tect√©s et les trims effectu√©s.

‚∏ª

üéØ Statistiques dans trim_log.txt
	‚Ä¢	Total reads processed : Nombre total de reads analys√©s.
	‚Ä¢	Total reads trimmed : Nombre de reads qui ont √©t√© modifi√©s (coup√©s).
	‚Ä¢	PolyA trims : Nombre de trims dus √† la d√©tection de la queue polyA.
	‚Ä¢	Motif trims : Compte du nombre de fois que chaque motif a √©t√© trouv√© et coup√©.

‚∏ª

üí° Am√©liorations possibles :
	‚Ä¢	Ajouter une fonctionnalit√© pour que le script prenne en charge plusieurs fichiers en entr√©e/sortie (batch processing).
	‚Ä¢	G√©n√©rer un fichier de sortie avec les motifs d√©tect√©s dans chaque read pour une analyse plus pouss√©e.

Si tu as besoin d‚Äôautres ajustements, n‚Äôh√©site pas √† me le dire ! üòä








Pour effectuer un subsampling (√©chantillonnage al√©atoire) de fichiers FASTQ, plusieurs outils logiciels sont disponibles, chacun ayant ses propres caract√©ristiques. Voici quelques options populaires :

1. seqtk
	‚Ä¢	Description : seqtk est un outil rapide et l√©ger pour manipuler les fichiers FASTA/FASTQ. Il permet de faire un √©chantillonnage al√©atoire d‚Äôun pourcentage ou d‚Äôun nombre fixe de s√©quences.
	‚Ä¢	Installation :

sudo apt-get install seqtk


	‚Ä¢	Commande pour subsampling :

seqtk sample input.fastq 0.1 > output.fastq

Cela prendra un √©chantillon de 10 % des s√©quences dans input.fastq et l‚Äôenregistrera dans output.fastq.

2. BBTools (bbduk.sh)
	‚Ä¢	Description : Le package BBTools contient un ensemble d‚Äôoutils pour manipuler les donn√©es de s√©quences, y compris bbduk.sh, qui peut √™tre utilis√© pour √©chantillonner les fichiers FASTQ.
	‚Ä¢	Installation : T√©l√©chargez depuis BBTools.
	‚Ä¢	Commande pour subsampling :

bbduk.sh in=input.fastq out=output.fastq k=12 ref=adapters.fasta

Vous pouvez ajuster le pourcentage ou le nombre de s√©quences √† conserver en jouant avec les param√®tres de l‚Äôoutil.

3. Fastq-tools
	‚Ä¢	Description : C‚Äôest un autre ensemble d‚Äôoutils pratiques pour manipuler les fichiers FASTQ, notamment pour effectuer du subsampling.
	‚Ä¢	Installation :

sudo apt-get install fastq-tools


	‚Ä¢	Commande pour subsampling :

fastq-clipper -s 0.1 input.fastq output.fastq

Cela permet de pr√©lever un √©chantillon de 10 % des s√©quences.

4. shuf (Unix)
	‚Ä¢	Description : Si vous pr√©f√©rez une m√©thode plus g√©n√©rale et simple, shuf est un utilitaire Unix qui permet de m√©langer les lignes de fichiers, et peut √™tre utilis√© pour faire du subsampling.
	‚Ä¢	Commande pour subsampling :

shuf -n 100000 input.fastq > output.fastq

Cela extrait 100 000 lignes du fichier d‚Äôentr√©e.

5. FASTQ-MJ
	‚Ä¢	Description : Un outil Python l√©ger pour effectuer du subsampling sur des fichiers FASTQ.
	‚Ä¢	Installation :

pip install fastq-mj


	‚Ä¢	Commande pour subsampling :

fastq-mj -i input.fastq -o output.fastq -p 0.1

Cela extrait un √©chantillon de 10 % des s√©quences.

Ces outils sont tous performants et permettent de manipuler les fichiers FASTQ facilement. Choisissez celui qui convient le mieux √† vos besoins et √† votre environnement.





Test de https://github.com/lh3/seqtk 




zcat tara_reads_R1.fastq.gz | wc -1
zcat tara_reads_R1.fastq.gz | head -n 20



seqtk sample -s200 tara_reads_R1.fastq.gz 5000 > tara_reads_R1.fastq
seqtk sample -s200 tara_reads_R1.fastq.gz 5000 > tara_reads_R2.fastq








./view_fastq_head.sh data/processed_data/trimmed_data_test/BC_0076_R1_trimmed.fastq.gz 80
Showing first 80 lines of data/processed_data/trimmed_data_test/BC_0076_R1_trimmed.fastq.gz:
----------------------------------------
@LH00611:18:225KMWLT1:2:1101:1203:1096 1:N:0:CAGATC
GNAGTGGTATCAACGCAGAGTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGT
+
I#IIII9I9IIIIIIIIIII9IIII*IIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIIIIIIII*IIIIIII9IIIII9IIIII9I9I9IIII9*IIIIIIII9IIIIIIIIIIII99I*IIIIIIII99II99IIII
@LH00611:18:225KMWLT1:2:1101:1277:1096 1:N:0:CAGATC
ANTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGTGGCGAGCGAACGGGGACTAGCCCTTCAGCTTCTTTGATTTTCGCGGCACGCTCTGGAAAGTGCGGCCATAGTGGGTGATCGCCCTGTACGCGAAAGGATCTTCGAAGTGAAAT
+
I#I*IIIII9IIIIIIIIIIIIIIIIIIIIIIIIIII9II9IIIIIIIIII9IIII9IIIIIIIIIIII9II*I9IIIIII99I9IIIIIIIIIIII*IIII**I9IIII9*I9II9*9II**I*I99*999I9I9*9*99*9**II9999*9999I*9*9IIIII*II
@LH00611:18:225KMWLT1:2:1101:1499:1096 1:N:0:CAGATC
GNGAATACGTTCCCGGGCCTTACACACACCGCCCGTCACACCATGGGAGTGGGTTGCACCAGAAGTAGCTAGTCTAACCTTCGGGAGGACGGTTACCACGGTGTGATTCATGACTGGGGTG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1703:1096 1:N:0:CAGATC
ANCAGTGGTATCAACGCAGAGTGAATGGGGGTCAAGTGAAGAAGCGCATACGGTGGATGCCTTGGCAGTCAGAGGCGATGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCG
+
I#IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1740:1096 1:N:0:CAGATC
GNTGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCGGAGATGTCTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGGAAAAGAAATCAACCGAGATTCCCTTAGTAGTGGCGAGCGAACGGGGACTAGCCCTTAAGCTTCTTTGATTTTG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIII*II9IIIIIII*IIII*
@LH00611:18:225KMWLT1:2:1101:1758:1096 1:N:0:CAGATC
CNAAGTTTAAGGTGGTAGGCTGAATCTTAGGTAAATCCGGGATTCTAAGGCCGAGAGCTGATGACGAGTTACCCTTTGGGTGACGAAGTGGTTGATGCCATGCTTCCAAAAAGG
+
9#9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIII9II99IIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1777:1096 1:N:0:CAGATC
ANGCAGTGGTATCAACGCAGAGTGAATGGGAAAGACCCCGTGAACCTTTACTATAGCTTTGCACTGGACTTTGAATTTGCTTGTGTAGGATAGGTGGGAGGCTTTGAAGCGTGGACGCCAGTTCGCGTGGAGCCATCCTTGAAATACCACCCTGGCAACTTTGAGGTTCTAACTCA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1814:1096 1:N:0:CAGATC
CNTTGATCCGGAGATGTCTGAATGGGGGAACCCAGCCATCATAAGATGGTTATCTTGTACTGAATACATAGGTGCAAGAGGCGAACCAGGGGAACTGAAACATCTAAGTACCCTGAGG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:1832:1096 1:N:0:CAGATC
TNGTTGTCCAAGTTTAAGGTGGTAGGCTGGAATCTTAGGTAAATCCGGGATTCTAAGGCCGAGAGCTGATGACGAGTTACCCTTTGGGTGACGAAGTGGTTGATGCCATGCTTCCAAGAAAAGCTTCTAA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIII9
@LH00611:18:225KMWLT1:2:1101:2165:1096 1:N:0:CAGATC
ANCGCATACGTCCTACGGGAGAAAGCAGGGGACCTTCGGGCCTTGCGCTATCAGATGAGCCTAGGTCGGATTAGCTAGTTGGTGAGGTAATGGCTCACCAAGGCGACGATCCGTAA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2442:1096 1:N:0:CAGATC
GNTATCAACGCAGAGTGAATGGGGGTCAAGTGAAGAAGCGCATACGGTGGATGCCTTGGCAGTCAGAGGCGATGAAAGACGTGGTAGCCTGCGAAAAGCTTCGGGGAGTCGGCAAACAGACTTTGATCCGGAG
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:2535:1096 1:N:0:CAGATC
CNCCCTTTAAAGAAAGCGTAATAGCTCACTAGTCGAGTCGGCCTGCGCGGAAGATGTAACGGGGCTCAAACCATACACCGAAGCTACGGGTATCACGTAAGTGATGCGGTAGAGGAGCGTTCTGTAAGCCTGTGAAGGTGAGTTGAGAAGCTTGCTGGAG
+
I#IIIIIII*III9IIIIIIIII9IIIII*IIIII9IIIIIIIIII9IIII9I*I9IIIIII9IIIIIIIII9IIIII9IIIIIIIIIIIIIII99I9IIIIIIIIIIIIIIIIIIIII9III9IIIII*IIIIIII*IIIIIIIIIIIIIIII9IIII9
@LH00611:18:225KMWLT1:2:1101:2997:1096 1:N:0:CAGATC
GNCATGCCGCGTGTGTGAAGAAGGTCTTCGGATTGTAAAGCACCTTAAGTTGGGAGGAAGGGCATTAACCTAATACGTTAGTGTTTTGACGTTACCGACAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCGCGTAGGTGGTTCGTTAAGTTGGATGTAAATCCCCGGGCTCAACCTGGGAACNGCA
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII*IIIIIIIIIIIIIIIIIIIIIIIII9II9IIIIIIIIIIIIIIIIIIIIIIIIIII9II9IIII#III
@LH00611:18:225KMWLT1:2:1101:3034:1096 1:N:0:CAGATC
CNTGGACTGATACTGACACTGAGGTGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCAACTAGCCGTTGGGAGCCTTGAGCTCTTAGTGGCGCAGCTAACGCATTAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTAAAAC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIII*IIIIIIII
@LH00611:18:225KMWLT1:2:1101:3219:1096 1:N:0:CAGATC
GNAGTGAAATCGAGTAGGACGGAGCACGAGAAACTTTGTCTGAATATGGGGGGACCATCCTCCAAGGCTAAATACTACTGACTGACCGATAGTGAACTAGTACCGTGAGGGAAAGGCGAAAAGAACCCCTGAGAGGGGAGTGAAATAGATCCTGAAACCGTATGCGTACAAGCAGTGGGAGCCCACTTTGTTGGGTGACTGCGTACCTTTTGTATAATGGGTCAGCGACTATACCACAGTC
+
I#IIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIII9IIII9II9IIII
@LH00611:18:225KMWLT1:2:1101:3293:1096 1:N:0:CAGATC
ANGCAGTGGTATCAACGCAGAGTGAATGGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGTCAACTAGCCGTTGGGAGCCTTGAGCTCTTAGTGGCGCAGCTAACGCATTAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTAAAACTC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3330:1096 1:N:0:CAGATC
GNGGTATCAACGCAGAGTGAATGGGGACTAGCCCTTAAGCTTCTTTGATTTTAGCGGAACGCTCTGGAAAGTGCGGCCATAGTGGGTGATAGCCCTGTACGCGAAAGGATCTTAGAAGTGAAATCGAGTAGGACGGAGCACGAGAAACTTTGTCTGAATATGGGGGGACCATCCTCCAAGGCTAAATACTACTGACTGACCGATAGTGAACTAGTGCCAATATCCACAGTCTCAAGCACGT
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII9IIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3459:1096 1:N:0:CAGATC
CNGCACGAATGGCGTAACGAT
+
I#IIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3533:1096 1:N:0:CAGATC
ANGCAGTGGTATCAACGCAGAGTGAATGGGAGACACACGGCGGGTGCTAACGTCCGTC
+
I#IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
@LH00611:18:225KMWLT1:2:1101:3774:1096 1:N:0:CAGATC
ANAGTATGGTAGAGGGTGGTGGAATTTCCTGTGTAGCGGTGAAATGCGTAGATATAGGAAGGAACACCAGTG
+
I#99IIIIIIIIIIIIIIIII9I*IIIIII9III9II9II*II9I9IIIIIII**I9III9I9IIIIIIIII
vgoupille@genossh:/projects/ecogeno/DEV/2025_GoupilleValentin$ 







Tu as raison, je me suis tromp√© dans l‚Äôinterpr√©tation‚ÄØ:  
Dans les fichiers Cutadapt, la valeur "input" dans "read_counts" correspond au nombre de reads pour chaque fichier (R1 et R2), et non la somme des deux.  
Donc, **Total R1 = "input"** (et Total R2 = "input" aussi, car paired-end).

Corrigeons le tableau‚ÄØ:

### Valeurs corrig√©es

#### BC_0076
- Total R1 = 631‚ÄØ393‚ÄØ326
- R1 avec TSO retir√© = 153‚ÄØ472‚ÄØ373
- Pourcentage = (153‚ÄØ472‚ÄØ373 / 631‚ÄØ393‚ÄØ326) √ó 100 ‚âà **24,3‚ÄØ%**

#### BC_0077
- Total R1 = 325‚ÄØ495‚ÄØ590
- R1 avec TSO retir√© = 90‚ÄØ142‚ÄØ002
- Pourcentage = (90‚ÄØ142‚ÄØ002 / 325‚ÄØ495‚ÄØ590) √ó 100 ‚âà **27,7‚ÄØ%**

#### BC_0079
- Total R1 = 379‚ÄØ108‚ÄØ253
- R1 avec TSO retir√© = 102‚ÄØ386‚ÄØ519
- Pourcentage = (102‚ÄØ386‚ÄØ519 / 379‚ÄØ108‚ÄØ253) √ó 100 ‚âà **27,0‚ÄØ%**

#### BC_0080
- Total R1 = 397‚ÄØ654‚ÄØ767
- R1 avec TSO retir√© = 99‚ÄØ430‚ÄØ515
- Pourcentage = (99‚ÄØ430‚ÄØ515 / 397‚ÄØ654‚ÄØ767) √ó 100 ‚âà **25,0‚ÄØ%**

---

| √âchantillon | Total R1         | R1 avec TSO retir√© | Pourcentage (%) |
|-------------|------------------|--------------------|-----------------|
| BC_0076     | 631‚ÄØ393‚ÄØ326      | 153‚ÄØ472‚ÄØ373        | 24,3            |
| BC_0077     | 325‚ÄØ495‚ÄØ590      | 90‚ÄØ142‚ÄØ002         | 27,7            |
| BC_0079     | 379‚ÄØ108‚ÄØ253      | 102‚ÄØ386‚ÄØ519        | 27,0            |
| BC_0080     | 397‚ÄØ654‚ÄØ767      | 99‚ÄØ430‚ÄØ515         | 25,0            |

Merci pour ta vigilance‚ÄØ!  
Dis-moi si tu veux le code pour automatiser ce calcul sur tous tes fichiers.




Here is a concise explanation in English, suitable for your "Materials and Methods" section, describing preprocessing (trimming), quality control, and STARsolo alignment on the GenOuest cluster.  
Je commente en anglais pour t‚Äôaider √† l‚Äôint√©grer facilement.

---

**Preprocessing, Quality Control, and Alignment on the GenOuest Cluster**

All preprocessing and alignment steps were performed on the GenOuest high-performance computing cluster to ensure efficient handling of large sequencing datasets.

- **Trimming and Quality Control:**  
  Raw sequencing reads were first subjected to quality control using FastQC and MultiQC to assess overall read quality and identify potential technical artifacts. Trimming was performed using Fastp and Cutadapt in a multi-step pipeline. This included removal of template-switching oligo (TSO) sequences from R1, trimming of low-quality bases and polyG/polyX tails, polyA and adapter removal, and final length filtering. All steps were executed in paired-end mode to maintain synchronization between R1 and R2 files. After each trimming step, quality control was repeated to ensure the effectiveness of the process and to monitor improvements in read quality.

- **Alignment with STARsolo:**  
  High-quality, trimmed reads were aligned to the *Pseudomonas brassicacearum* reference genome using STARsolo, an extension of the STAR aligner optimized for single-cell RNA-seq data. STARsolo was chosen for its speed, reproducibility, and compatibility with the microSPLiT protocol. The alignment process included barcode and UMI extraction, as well as gene quantification at the single-cell level.

- **Cluster Environment:**  
  All analyses were automated using SLURM job scripts to efficiently utilize the computational resources of the GenOuest cluster. Resource usage (CPU, memory) was monitored and optimized for each step. The complete pipeline and scripts are available in the project‚Äôs GitHub repository.

---

// This paragraph summarizes the preprocessing (trimming), quality control, and STARsolo alignment steps, specifying that all analyses were performed on the GenOuest cluster, and highlights the use of FastQC, Fastp, Cutadapt, and STARsolo, as well as the automation with SLURM.

Si tu veux une version plus d√©taill√©e ou plus courte, ou l‚Äôint√©grer √† un endroit pr√©cis, pr√©cise-le !




atter}



- test de clustering sur l'ensemble ne marche pas car trop cellules en conditions stress avec trop faible exprssion donc clusterise par la profondeur entre les groupe cultures medium , hormis housekeeping gene pour lesquels on capte un peu de signal , voit bien mieux UMIs pour ces genes en conditions de stress 

choix de prendre seulement deux rep bio pour tester , √† 0D1 car prelevement en meme temps , et aussi max signal , facilite normalisation 








le choix de filtration sera discut√© apres

because the reads depth is different between : Stress condition (M9F) and non-stress condition (M9) et also between the 3 timepoints (T1, T2, T3) (voir figure, reuslttas comme deja observ√© chez )




## Test global sur l'ensembles des conditions voir si on peut voir des differences entre les conditions 

fait avec la methode de bacsc et classique (ici uniqement present√© les resultats de bacsc)


















































































The low saturation may be partially explained by the high complexity of the bacterial transcriptome and the large number of unique cell barcode combinations detected (699,355).









Our results align well with the expected performance metrics for single-cell RNA-seq in bacteria.


It is important to note that preliminary STARsolo tests without trimming yielded saturation values 0.94 **> 0.7**, which would have met the Gaisser et al. (@gaisser2024) recommendation for adequate sequencing depth. However, these elevated saturation values were not due to superior sequencing quality but rather to less effectively trimmed reads that artificially affected the saturation ratio. The lower saturation observed in our final analysis with proper trimming (0.0097) actually reflects more accurate data quality assessment, as the trimming process removed sequencing artifacts and low-quality reads that would have otherwise inflated the saturation metric. This observation suggests that the interpretation of saturation values in the Gaisser et al.(@gaisser2024) study may need revision, as their trimming protocol reportedly left approximately 10% of TSO sequences remaining, which could have artificially inflated their saturation metrics. While our saturation value of 0.97% falls well below their recommended threshold of >0.7, this difference likely reflects the superior quality of our trimming protocol rather than inadequate sequencing depth. The low saturation value (0.97%) indicates minimal redundancy in our sequencing data, suggesting that a substantial portion of the transcriptome remains unexplored. This implies that deeper sequencing could potentially capture additional unique transcripts and provide more comprehensive coverage of the transcriptional landscape.


peut etre devoir verifier les 4 biblioteques pour comprendre les differences de duplication et voir si differences de satureation 




For our division of labor analysis focusing on mRNA expression patterns, these highly abundant non-coding RNAs will need to be filtered out to avoid masking subtle transcriptional differences between subpopulations. This information is crucial for understanding the transcriptional landscape and identifying potential division of labor patterns, as different RNA types may be differentially expressed across subpopulations.



**Key considerations for division of labor analysis:**
- The choice of filtering threshold can significantly impact the detection of rare subpopulations
- Housekeeping genes and rRNA content may provide insights into growth rate variations across cells
- Technical replicates may need to be pooled or analyzed separately depending on experimental design





## Overview of single-cell RNA-seq methods in bacteria {#sec-appendix-nishimura}

![Overview of bacterial single-cell RNA sequencing approaches. (A) Schematic summary of single-cell isolation strategies employed in bacterial single-cell RNA-seq, highlighting the key features and distinctions of each approach. FACS, fluorescent activated cell sorting; UMI, unique molecular identifier. (B) Summary of features of each bacterial single-cell RNA-seq method, including MATQ-seq, RamDA-seq, PETRI-seq, microSPLiT, BacDrop, ProBac-seq, M3-seq, and smRandom-seq @nishimura2025 ](../figures/nishimura_review.jpg){#fig-nishimura_review fig-alt="Overview of bacterial single-cell RNA sequencing approaches" fig-cap="Fig. 1. Overview of bacterial single-cell RNA sequencing approaches. (A) Schematic summary of single-cell isolation strategies employed in bacterial single-cell RNA-seq, highlighting the key features and distinctions of each approach. FACS, fluorescent activated cell sorting; UMI, unique molecular identifier. (B) Summary of features of each bacterial single-cell RNA-seq method, including MATQ-seq, RamDA-seq, PETRI-seq, microSPLiT, BacDrop, ProBac-seq, M3-seq, and smRandom-seq. Adapted from Nishimura et al. (2025) [@nishimura2025]."}

## MicroSPLiT sequencing library preparation

![MicroSPLiT sequencing library preparation. a, Selected sub-libraries with barcoded cells are lysed. Because cDNA molecules primed with both random hexamer and poly-dT primers undergo the same downstream reactions, only one of them is shown for clarity. b, After lysis, cDNA is purified via streptavidin beads. The cells then undergo an additional RT and template switching step. The template switch primer has two RNA G bases and a locked nucleic acid G base ('rGrG+G') sequence to facilitate the binding. c, cDNA is amplified, and size is selected to eliminate the unwanted short product ('dimer') from the cDNA amplification product. At this point, the size and concentration of the cDNA product are quantified (Part 2, Step 127). d, The library then undergoes fragmentation and adapter ligation. The desired sequencing product containing the barcodes is amplified with the primers for both the third barcode adapter and the ligation adapter, which contain Read 1 (R1) and Read 2 (R2) sequences. Illumina P5 and P7 sequence adapters and a final sub-library index are also appended at this final PCR step . e, A 0.5‚Äì0.7√ó double size selection then selects out unwanted fragments. The final product's concentration and size are measured before sequencing .](../figures/protocol_p2.png){#fig-protocol-p2 fig-alt="MicroSPLiT sequencing library preparation" fig-cap="MicroSPLiT sequencing library preparation."}

## TSO removal statistics {#sec-appendix-tso}

The following table summarizes the number of R1 reads before and after TSO removal for each sample, as well as the corresponding percentage.

| Sample    | Total R1     | R1 with TSO removed | Percentage (%) |
|-----------|--------------|--------------------|----------------|
| BC_0076   | 631,393,326  | 153,472,373        | 24.3           |
| BC_0077   | 325,495,590  | 90,142,002         | 27.7           |
| BC_0079   | 379,108,253  | 102,386,519        | 27.0           |
| BC_0080   | 397,654,767  | 99,430,515         | 25.0           |

: TSO removal statistics for each sample. The table shows the total number of R1 reads, the number of R1 reads after TSO sequence removal, and the corresponding percentage. {#tbl-tso-removal}

// Table added to summarize TSO removal efficiency for each sample.
// ... existing code ...